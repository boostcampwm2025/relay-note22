# 2주차 Relay-Project - 기존 주제에 대한 토론

## 🤔우리가 느낀 공통의 고민

- 성장을 위해 AI를 사용하는 것은 좋지만 어디가 **Dead-Line** 인가?
- 구현 방식이 떠오르지 않아서 AI에게 도움을 받은 코드를 해석하는 것도 학습인가?
- 구현하는 것도 중요하지만 내 학습과 설명을 문서화하는 것도 중요한데, 점점 소홀해지는 것은 아닐까?
  - AI에게 문서화를 도움 받을 순 없을까?
- 하루의 시간 관리를 어떻게 해야 할까?
- AI가 정말 컨디션 관리에 도움을 줄 수 있는가?
  - 지킬 수 없는 하루 루틴이나 시간표를 추천 받는 것 보다 실용성 있는 활용 방법은 없을까?

## 우리의 결론

- AI의 도움을 받는 것은 좋지만 주도권은 나에게 있어야 한다.
  - 코드를 대신 작성해주는 것은 귀찮은 부분을 맡기는 것이지 내 학습과 고민 과정을 맡겨서는 안 된다.
  - 리팩토링과 피드백 관점에서 사용은 권장하지만 내가 생각할 부분을 전부 넘겨서는 안 된다.
- AI를 실제로 일정, 피로도 관리 측면에서 실제로 사용하기는 어려울 것 같고 기분 전환 같은 가벼운 영역은 괜찮은 것 같다.

## 기존 주제에 대한 토론

AI와 함께 성장하자는 주제도 좋고, 성장을 위해 AI를 활용한다는 취지에 맞게 미션들도 잘 구성되어 있다. <br/>

1. 그날의 기분이나 컨디션을 그림으로 표현하기
2. AI에게 오늘 아쉬웠던 점을 이야기하고, 격려와 응원을 받아보기
3. AI에게 학습 내용 정리를 토대로 가벼운 퀴즈를 내는 걸 부탁하기
4. 어제의 README, 오늘의 README를 AI에게 맡겨서 어느 부분에서 성장했는가를 확인하기

모든 미션이 좋은 취지를 가지고 있으나 **성장을 위해 AI를 활용한다** 는 주제에 맞추자면 <br/>
3, 4번 미션은 유지해도 좋을 것 같고 1, 2번 미션은 수정할 여지가 있어 보인다.

## 결론

1, 2번 미션은 새로운 미션으로 교체를 하고 <br/>
3, 4번 미션은 기존 미션을 업그레이드하기로 했습니다.

## 새로운 미션에 대한 아이디어

1. 학습목표를 보고 본인이 배경지식을 공부한 뒤 AI의 도움 없이 요약본을 작성하여 AI에게 점수제로 평가해달라고 하기

- 평일에 실질적인 활용이 어려울 경우 주말에 이용하도록 한다.

2. 스스로 규칙을 정하여 AI의 도움 없이 코드를 작성한 뒤 내가 세운 규칙을 잘 지켜서 작성했는지 분석 요청하기

- 피어 세션 전에는 피드백을 받을 수 없으니 AI의 도움을 받아서 피드백을 받는다.

3. 본인이 정리한 학습 내용을 토대로 AI 암기 노래 만들기
4. 요구사항을 분석하고 정리한 뒤 AI에게 규칙을 추천받아 해당 규칙을 지키면서 구현을 한다.
5. 체크포인트에 체크하는 행위를 AI에게 부탁하기

- AI의 분석을 토대로 진짜로 만족하고 있는가? 평가하기

6. README 내용을 토대로 나의 시점에 몰입하여 회고록 작성을 부탁하기
7. AI에게 미션에 대한 키워드를 제공해주고 3분 토론하기
8. 개발자는 영어도 잘 해야 하는데, 영어 공부하기 좋은 팝송 추천 받기
9. 학습을 진행하며 다양한 LLM 모델을 사용하는데, 나에게 가장 잘 맞는 모델은 무엇인지 분석하기

## 미션1 수정 내용

- 학습목표를 보고 본인이 배경지식을 공부한 뒤 AI의 도움 없이 요약본을 작성하여 AI에게 점수제로 평가해달라고 하기

🔹목표: 학습목표를 이루기 위한 기본 배경지식들을 선정한 후 학습한 뒤, 본인의 언어로 핵심을 요약 가능한지, 이해한 상태로 구현에 들어갈 수 있는지 스스로 점검하는 튜터를 AI에게 부탁한다.<br>

🔹의의: 우리는 현재 매우 많은 정보를 받아들이는 데에만 익숙해져있다. 학습에서 중요한 부분인 기억 인출 및 재조립을 시도한다. 본인의 언어로 설명하는 것은 메타인지의 첫걸음이다.<br>

✔️달성 기준: AI가 80/100점 이상으로 평가 시 통과<br>

🎯방법: \<학습목표(해당 미션 학습 목표 참고)\> + <선정된 개발 키워드> + <내가 요약한 요약문> + "위 학습목표에 대해 내가 요약한 요약문을 100만점으로 평가해줘" 프롬프트로 보낸다.

✔️조건: 내가 요약한 요약문은 어떠한 글 자료나 AI의 도움없이 오로지 본인의 기억만으로 작성한다.

- 내가 이해한 내용을 바탕으로 한 언어를 AI에게 평가받고, 부족하다고 평가되거나 누락되었다고 피드백받은 부분을 집중 공부하기
- 슬랙이나 피어 피드백 시간에 팀원과 공유해보기

##### 예시

- prompt:

학습 목표: 가상 파일 시스템과 테스트

개발 키워드: 파일시스템, Jest, Mocha

요약: 파일시스템은 컴퓨터의 데이터를 논리적이고 일관적인 구조로 접근하고 관리하기 위해 도입되었다.
리눅스는 파일과 디렉토리 모두 '파일'로 취급하며, 각 파일의 접근 권한, 생성 일자, 크기, 생성 계정 등 메타 정보도
같이 기록된다. 파일 시스템은 리눅스의 fat32, xfs, ext4 등, 윈도우의 NTFS 등 다양한 파일 시스템이 있으며, virtual file system은
이러한 구체적인 파일 시스템을 추상화하여 서로 다른 파일 시스템에 대한 접근을 통일된 APi로 응용프로그램이 접근할 수
있도록 돕는다. 테스트는 소프트웨어 개발을 버그없이 잘 동작함을 자동적으로 평가하기 위해 실시하며, 단위 테스트,
통합 테스트, e2e테스트 등 목적과 범위에 따라서 다양하게 존재한다. Jest와 Mocha는 Javascript의 테스트 라이브러리이며
Jest는 개인 사용자의 편의성, Mocha는 상대적으로 확장성과 복잡한 테스트 구현에 강점이 있다. 둘 모두 expect, it, test, describe
과 같은 matcher를 제공하며, 직관적인 문법으로 .test.js나 .spec.js를 모두 찾아 자동적으로 실행한다.

위 학습목표에 대해 내가 요약한 요약문을 100만점으로 평가해줘

- 결과

평가 총점: 990,000 / 1,000,000
평가 근거

| 평가 항목              | 점수 (만점 대비) | 평가 내용                                                                                                                                                                     |
| ---------------------- | ---------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **정확성**             | 100%             | 파일 시스템의 정의, 리눅스의 모든 것을 파일로 취급하는 모델, VFS의 추상화 목적, 테스트 개념, Jest/Mocha 비교 설명이 정확함.                                                   |
| **개념 포괄성**        | 95%              | 테스트 범주에서 e2e 테스트와 통합 테스트, 단위 테스트를 열거했으나, 각 테스트의 목적 차이를 한 문장 정도로만이라도 명확히 구분했으면 더 포괄적이었음.                         |
| **논리적 흐름**        | 100%             | 파일 시스템 → VFS → 테스트 → JS 테스트 프레임워크 순으로 개념적 전개가 자연스러움.                                                                                            |
| **용어 사용의 엄밀성** | 99%              | 대부분 정확하나, ‘fat32’를 리눅스에서만 예시한 부분은 FAT32가 윈도우 기반 파일 시스템에서 먼저 설계된 점을 명시해도 더 학술적으로 완벽했음. ext4, xfs는 리눅스 전용으로 적합. |
| **간결성 및 명료성**   | 98%              | 문장이 압축적이며 일관성 있음. 다만 Jest/Mocha의 차이를 문법이 아닌 실행 속도, coverage 지원, 생태계 규모 측면에서도 한 문장 추가하면 더 균형적이었음.                        |

종합 코멘트

해당 요약은 파일 시스템과 테스트 학습 목표를 고도의 정확성, 개념적 완결성, 논리적 일관성을 바탕으로 기술하였으며, 실무 학습이나 논문 개요에서도 바로 활용 가능한 수준이다.

개선 여지:

각 테스트 유형(e.g. 단위, 통합, e2e) 목적과 범위를 구분 정의

FAT32의 역사적 기원(윈도우 기반)과 리눅스 지원 맥락 간단 명시

Jest와 Mocha의 추가 비교(coverage, mock 지원, 생태계 규모 등)

- 느낀 점

느낀 점: 테스트 커버리지(Test Coverage)는 작성된 테스트 코드가 실제 코드의 어느 부분을 얼마나 실행하고 있는지 측정하는 지표이다. 새로운 구멍을 알았다!

## 📜 미션 2. AI를 학습에 사용할 때 근거 레퍼런스 자료를 요청하고 분석하기

### 미션 배경

마스터 `JK`님께서 슬랙에서 하셨던 말씀 중에 이런 말이 있었습니다. <br/>

- GPT는 레퍼런스 체크가 필수입니다. 점점 나아지고 있지만 여전히 정확도는 떨어집니다.
- 검색을 할 때도 한글 자료가 많으면 아직 하류에 머물러 있구나 하고 의도적으로 상류로 올라가보세요.
  영어 자료만 있거나 공식 문서 이외에 자료가 별로 없다면 원천지 근처까지 다가간 걸 겁니다. 그런 상황에 점차 익숙해지셔야 합니다.

### 미션 목표

- [ ] GPT가 제공해준 학습, 요약 자료를 보고 실제 레퍼런스 자료와 비교해 보기
- [ ] 영어로 된 레퍼런스 자료를 준다면 해당 자료를 직접 검색해서 찾아보기
- [ ] 영어 자료만 있거나 공식 문서 이외에 자료가 별로 없다면 슬랙에 공유하여 스스로를 칭찬하기 (선택)

## 미션 3 업그레이드 내용

기존 미션은 AI에게 학습정리를 토대로 가벼운 퀴즈를 내고 푸는 미션이었음<br/>
이 기존 미션에 구체적인 조건을 추가하고자 함

### 추가 조건

1. 프롬프트 구체화

- 퀴즈의 형식을 특정해서 구체적으로 어떠한 형식으로 문제를 출제할 지 제시(주관식, 객관식, 빈칸문제, O/X문제 등)

2. 슬랙에 퀴즈 공유

- Random 채널 등을 활용해서 당일 미션에 대한 퀴즈를 생성하여 동료들에게 공유하여 커뮤니티 활성화

3. 퀴즈에 대한 검증

- 항상 옳은 정답만을 제시하지는 않기 때문에 퀴즈를 풀고 제시한 답이 정말 옳은지 검증

위의 조건 중 하나 이상을 충족하도록 미션을 진행하고, 릴레이 노트에 과정을 기록함

## 미션 4. 오늘의 나, 내일의 나: AI와 함께하는 성장 미션

어제보다 더 나은 오늘을 위한 특별한 성장 미션에 참여해보세요! AI가 당신의 README를 분석해 맞춤형 피드백을 제공하고, 이를 바탕으로 꾸준히 발전하는 자신을 발견할 수 있습니다.

미션 목표: AI 회고를 통해 스스로 부족한 부분을 파악하고, 다음 미션에서 개선 사항을 실천하며 지속적인 성장을 경험합니다.

미션 수행 방법:

1. AI에게 README 제출: 매일 작성한 README를 AI에게 제출해주세요.

2. AI 회고록 기록: AI가 제공하는 회고록을 블로그나 개인 README 등 원하는 공간에 기록하고 보관합니다.

3. 다음 미션에 회고 적용: 다음 날 미션을 수행할 때는 어제의 AI 회고록 내용을 참고하여 부족했던 부분을 개선하고, 새로운 목표를 설정하여 실천합니다.

이 미션은 여러분이 꾸준히 자신을 되돌아보고 발전하는 데 도움을 줄 것입니다. AI와 함께 한 걸음씩 성장해나가는 경험을 지금 바로 시작해보세요!

---

### 선정한 퀘스트

K013 류경록 : 미션 2. AI를 학습에 사용할 때 근거 레퍼런스 자료를 요청하고 분석하기

- 🔥 이유: AI 자료들의 출처를 파악하여 더 확실한 학습을 하기 위해서 선택했다.

<details>
<summary>결과</summary>

## 질문

git clone의 원리에 대해 이해하고 싶어 너가 참고한 레퍼런스의 출처를 밝히면서 설명해줘

## 답변

```kotlin
4. 주요 레퍼런스
공식 Git 문서

Git Internals: https://git-scm.com/book/en/v2/Git-Internals-Git-Objects
Transfer Protocols: https://git-scm.com/book/en/v2/Git-Internals-Transfer-Protocols
Pack Protocol: https://git-scm.com/docs/pack-protocol

RFC 및 기술 명세

Git Protocol Specification: https://github.com/git/git/blob/master/Documentation/technical/protocol-v2.txt
Pack Format: https://github.com/git/git/blob/master/Documentation/technical/pack-format.txt

심화 학습 자료

"Building Git" by James Coglan: Git 내부 구조를 단계별로 구현하는 책
"Pro Git" by Scott Chacon: 2장 Git Internals 부분이 특히 유용
Git Source Code: https://github.com/git/git (특히 builtin/clone.c)
```

생각보다 출처가 명확하게 잘 나왔다.

공식 레퍼런스에서 어떤 부분을 봐야 하는지, 어디에 무엇이 적혀있는지 갈피를 못 잡는 상황에서는 이런 식으로 AI에게 먼저 물어보고 제공받은 링크로 넘어가서 학습을 진행하는 것도 자료 탐색 시간을 크게 단축시켜주는 효과가 있을 것 같습니다.

특히 좋은 점은 단순히 링크만 던져주는 게 아니라, 앞서 간단한 요약과 설명을 제공한 다음 레퍼런스를 제시하는 순서라는 것입니다. 이렇게 하면 그냥 AI의 말을 맹신하고 진행하는 것보다, AI가 요약해준 설명을 먼저 이해한 후 공식 레퍼런스로 들어가서 내용이 맞는지 틀린지 직접 검증할 수 있어서 훨씬 유용해 보입니다.

</details>

---

J028 김근선 : 미션 3 업그레이드 내용 (AI에게 학습 내용 정리를 토대로 가벼운 퀴즈를 내는 걸 부탁하기)

- 🔥 이유: reference를 찾고 검증하는 미션 2도 흥미롭지만 학습한 내용을 토대로 퀴즈를 만들어보는 미션 3번를 통해 공부한 개념을 더욱 깊이 이해하고 싶다!

<details>
<summary>결과</summary>

### ⚡️ 신경쓴 점

이번주는 미션 개선하기가 포함되어 있는 만큼 제대된 학습이 중요하다고 생각했어요. 그래서 AI에게 학습정리.md를 토대로 한 퀴즈를 요청해서 제가 공부한 내용을 재차 확인하려고 했던 것 같아요. 저는 보통 학습할 때 제가 쉬운 말로 풀어서 다른 사람에게 설명할 수 있게끔 공부를 합니다. 그래서 AI가 제게 주는 퀴즈도 그런 포맷에 맞춰서 요청했던 것 같아요. 또 슬랙에 공유하고 싶어서 문제는 어렵지 않고 누구나 "도전해볼까?"하는 퀴즈를 받을 수 있도록 입력 프롬프트 작성을 신경썼습니다.

추가로 이번 프로젝트에서는 다양한 문제 형식을 받는 걸 중요하게 생각했습니다. 예를 들어 "혹시 주관식, 객관식, 빈칸문제, O/X문제 등으로 해서 5문제 정도 간단하게 만들어줄 수 있어?" 라고 입력해서 variation을 줬습니다.

### ⚡️ 수행 과정 및 슬랙 공유

총 두 번의 퀴즈를 받아서 슬랙에 공유를 했습니다.

- 첫 번째 퀴즈~!

많은 분들이 참여하셨으면 해서 퀴즈를 푸신 분께 💯(백점)과 🏆(트로피)를 드린다는 조건을 추가했습니다.

![img1](https://private-user-images.githubusercontent.com/155948612/473284081-a635192c-7bbf-4aa2-8987-e0b9164afe5e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQwMjIyMjksIm5iZiI6MTc1NDAyMTkyOSwicGF0aCI6Ii8xNTU5NDg2MTIvNDczMjg0MDgxLWE2MzUxOTJjLTdiYmYtNGFhMi04OTg3LWUwYjkxNjRhZmU1ZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODAxJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgwMVQwNDE4NDlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03ODMzMzlkZjRjNjdhMTZlMTQxYzljNjAwZjZmNWMwNzA5ZmM3YTBjODQ3M2VmMDliNmY2YzBiMTE2MjM2OWI1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Ddf3DZzElUW0pxjX9YsQ-K8XdDtkN6JgDSs7_Zt7jHM)

![img2](https://private-user-images.githubusercontent.com/155948612/473284070-4e43b2cb-3725-4500-9c28-17d8f2990b5e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQwMjIyMjksIm5iZiI6MTc1NDAyMTkyOSwicGF0aCI6Ii8xNTU5NDg2MTIvNDczMjg0MDcwLTRlNDNiMmNiLTM3MjUtNDUwMC05YzI4LTE3ZDhmMjk5MGI1ZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODAxJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgwMVQwNDE4NDlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yZmExYzE4N2RkZDFkOTQyNDkxZjdkMmQ3ZDA4ZWZkZTI2Mzc0Zjg1ZTBhMGM4N2YyMzUxZmJlNWI3MWViOWRmJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.FHkalje0__y6Qpwb79zqzRc9xlxKJXo2IN4Pn6gE33c)

댓글로 많은 분들이 참여해주셨습니다ㅎㅎ! (JK님의 (머리가 안 식는 것 같아요)도 ㅋㅋ!!)

### ⚡️ AI라고 완벽하지 않다.

![ing](https://private-user-images.githubusercontent.com/155948612/473289607-90bec68b-ed43-48bb-9b19-b674ef132c45.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQwMjM0OTYsIm5iZiI6MTc1NDAyMzE5NiwicGF0aCI6Ii8xNTU5NDg2MTIvNDczMjg5NjA3LTkwYmVjNjhiLWVkNDMtNDhiYi05YjE5LWI2NzRlZjEzMmM0NS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODAxJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgwMVQwNDM5NTZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00ZTEyMTRiM2YwYzA4ZmNjOWExZmRjZWVlZWE4MWViNzcxM2MyODVkMzVlYzUwMWM2MjE4NGYxZDdiMjA2YTliJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.P1iQPJLophJ512RYIjPlO5Oa-BegCD_TzjYTf5f2lXs)

첫 번째 퀴즈에서 첫 번째 문제의 오류를 댓글에서 여러 피어 분들께서 발견해주셨습니다. 제 릴레이 프로젝트 미션 내용에는 퀴즈에 대한 검증도 포함되어 있었고, 그걸 눈으로 확인한 순간이었습니다.

AI는 똑똑하지만 항상 옳은 답을 제시하지는 않습니다. 그래서 개발자로서 AI를 사용할 때 항상 이런 교차 검증이 필요하다고 다시 한 번 깨달았습니다.

- 두 번째 퀴즈~!

![img3](https://private-user-images.githubusercontent.com/155948612/473290697-f6fba357-de81-4a87-ac70-ec18370431b7.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQwMjM5MzIsIm5iZiI6MTc1NDAyMzYzMiwicGF0aCI6Ii8xNTU5NDg2MTIvNDczMjkwNjk3LWY2ZmJhMzU3LWRlODEtNGE4Ny1hYzcwLWVjMTgzNzA0MzFiNy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODAxJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgwMVQwNDQ3MTJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kMGY1YzEwYzgzYTZmZTcxZDRkYWExZDE5NzZmY2I1NDdkNjg1MWNhMDE3OWM3NDVkNGE4MGU5OGQzMGEyYTllJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.lTOJipJNAYisa6zNAOHGHdpTXb8hX-KoutS5MlWU8rI)

월요일에 학습한 내용으로 퀴즈를 구성하여 리마인드의 목적을 두었습니다 ㅎㅎ😃

![img4](https://private-user-images.githubusercontent.com/155948612/473290903-8a9516d8-6782-4ac4-b7de-4d739708b934.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQwMjM5MzIsIm5iZiI6MTc1NDAyMzYzMiwicGF0aCI6Ii8xNTU5NDg2MTIvNDczMjkwOTAzLThhOTUxNmQ4LTY3ODItNGFjNC1iN2RlLTRkNzM5NzA4YjkzNC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODAxJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgwMVQwNDQ3MTJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yYmFlODU5OWViN2I3N2I0YjczNTY5YzNmODRmOGQ1YTQ0MWE0NzYwYzRmNDdjMTJhMzVkZTFlNDVkNTkxYTgwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.i7AfRxQRu2ZG8_pM9zQ6MbUrjqoihf4TQRDfS1v3wyk)
![img5](https://private-user-images.githubusercontent.com/155948612/473290948-66f54918-7c33-4434-be2f-7c50abbbecfc.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQwMjM5MzIsIm5iZiI6MTc1NDAyMzYzMiwicGF0aCI6Ii8xNTU5NDg2MTIvNDczMjkwOTQ4LTY2ZjU0OTE4LTdjMzMtNDQzNC1iZTJmLTdjNTBhYmJiZWNmYy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODAxJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgwMVQwNDQ3MTJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zMTQ2NTA4MGIyNWE4ZDA2YjQxNGY2NzU2YzRmNmYzZjNiZDBjZDEwZTdjY2JhODhmOWRhMjc1OTM5MjM0ZDU1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.fXij3H0QvR07uNg4u9aRueX5il_BDBO0zPsM4nW18uo)

저는 AI와 퀴즈를 만들면서 슬랙에 공유할 때, 피어분들이 퀴즈를 풀어 볼 마음이 생길수 있도록 너무 줄글이지 않은 다양한 문제들을 만들었는데요. 그러면서도 승원님이 댓글에서 짚어주신 것처럼 학습 중에서도 핵심 개념을 AI에게 요청해서 넣어봤습니다!

### ⚡️ 후기 및 다음에 고려하면 좋을 점

AI가 발전하고 그걸 활용하는 게 많이 당연시 된 것 같습니다. 하지만 AI라고 언제나 옳지는 않고 틀린 답을 내줄 때도 많은 것 같아요. 이번에 AI에게 퀴즈를 받으면서 학습을 할 수 있어서 도움이 됐지만, 첫 번째 퀴즈처럼 옳지 않은 지식을 학습할 수도 있다는 걸 경험했습니다. 이런 퀴즈 뿐만 아니라 다른 여러가지 방법으로 AI를 활용할 때도 항상 AI의 답변을 검증해야 한다는 생각을 가져야 될 것 같습니다. 만약 다음에 다른 피어분이 이 미션을 수행하게 된다면, 그리고 슬랙에 공유하게 된다면 퀴즈에 틀린 답을 심어두고 피어분들이 스스로 깨닫고 검증하는 경험을 할 수 있게 하면 많은 피어분들이 더 큰 인사이트를 얻을 것 같습니다. 물론 스스로 AI를 활용할 때도 더욱 경각식을 가지게 될 것이구요 ㅎㅎ!!

</details>

---

J145 송의현 : 미션 3 업그레이드 내용 (AI에게 학습 내용 정리를 토대로 가벼운 퀴즈를 내는 걸 부탁하기)

- 🔥 이유: 미션을 마무리하고 학습내용을 간단히 리마인드 하는 느낌으로 하면 좋을거 같아 선택

<details>
<summary>결과</summary>

### 퀴즈 1

**문제:**  
Git의 분산형 VCS에서는, 로컬에서 `git commit`을 수행해도 다른 사용자가 즉시 해당 변경 사항을 볼 수 있다. (O/X)

**정답:** ❌ X

- 분산형 VCS(Git)에서는 `git commit`은 **로컬 저장소에만 반영**됩니다.
- 다른 사용자가 보려면 `git push` 후, 상대방이 `git pull`을 해야 합니다.

---

### 퀴즈 2

**문제:**  
`git add` 명령어를 실행하면 Git은 파일 내용을 읽어 Blob 객체를 생성하고,  
그 해시값을 **Index(Staging Area)**에 기록한다. (O/X)

**정답:** ✅ O

- `git add` 시 Git은 파일 내용을 읽어 **Blob 객체**를 만들고,
- 그 해시값을 **Index(Staging Area)**에 기록합니다.

---

퀴즈 1
문제:
Node.js는 기본적으로 멀티 스레드 환경에서 동작하며, CPU 집약적 작업도 자동으로 여러 스레드에 분산된다. (O/X)

정답: ❌ X

Node.js는 기본적으로 싱글 스레드입니다.

CPU 병렬 처리를 위해서는 worker_threads 모듈로 별도 스레드를 생성해야 합니다.

퀴즈 2
문제:
process.nextTick은 이벤트 루프에서 Promise의 .then() 콜백보다 늦게 실행된다. (O/X)

정답: ❌ X

실행 순서: process.nextTick → Promise → setTimeout

## 따라서 nextTick이 Promise보다 먼저 실행됩니다.

</details>

---

J211 이종혁 : 미션 2. AI를 학습에 사용할 때 근거 레퍼런스 자료를 요청하고 분석하기

- 🔥 이유: AI의 레퍼런스 체크와 원본(과 비슷)한 자료로 추가학습을 위해서

<details>
<summary>결과</summary>

JS의 원시데이터/참조 데이터에 대해서 딥리서치 기능으로 질문한 뒤, 레퍼런스를 한 트위터 글에서 가져온걸 확인함
(링크)[https://x.com/finalchildmc/status/1664895964115607556]
이를 검증하기 위해 AI를 활용하여 V8 소스코드를 교차검증함

```
파차의 주장과 V8 소스코드 검증 요약
🎯 파차의 핵심 주장
"JS에서 원시 값은 스택에 저장되지 않습니다"
구체적 설명:

기본 전략: 모든 값을 힙에 할당하고, 스택에는 포인터만 저장
32비트 정수만 예외: V8에서 SMI(Small Integer)로 스택에 직접 저장
Tagged Pointer 메커니즘: 64비트 공간에서 마지막 비트로 포인터/직접값 구분
나머지 원시값: 문자열, 큰 정수, 부동소수점 등은 모두 힙에 저장

📋 V8 소스코드로 확인된 증거들
1. smi.h - 결정적 증거 ✅
cpp// Smi represents integer Numbers that can be stored in 31 bits.
// Smis are immediate which means they are NOT allocated in the heap.

"NOT allocated in the heap" = 힙에 할당되지 않음
"immediate" = 직접 저장됨

2. tagged-impl.h - Tagged Pointer 시스템 ✅
cppconstexpr bool IsSmi() const { return HAS_SMI_TAG(ptr_); }
constexpr inline bool IsStrong() const {
    return kCanBeWeak ? HAS_STRONG_HEAP_OBJECT_TAG(ptr_) : !IsSmi();
}

비트 태그로 Smi와 포인터 구분
Smi가 아닌 것은 HeapObject 포인터

3. string.h - 문자열은 힙 객체 ✅
cppV8_OBJECT class String : public Name {
V8_OBJECT class SeqOneByteString : public SeqString {
FLEXIBLE_ARRAY_MEMBER(Char, chars);

모든 문자열이 V8_OBJECT로 정의 = 힙 할당
가변 크기 데이터로 동적 할당 필요

4. objects.h - 전체 아키텍처 ✅
cpp// Extract the double value of a Number (Smi or HeapNumber).
static inline double NumberValue(Tagged<Number> obj);

숫자도 Smi 또는 HeapNumber로 구분
Tagged 시스템으로 모든 값 관리

🎯 결론: 파차의 주장은 100% 정확함
✅ 확인된 사실들:

32비트 정수(Smi): 스택에 직접 저장 (NOT allocated in the heap)
문자열: 모두 힙에 저장 (V8_OBJECT)
큰 정수/부동소수점: HeapNumber로 힙에 저장
Tagged Pointer: 비트 태그로 포인터/직접값 구분

📚 교육적 의미:

일반적인 오해: "원시값 = 스택, 객체 = 힙" ❌
실제 V8 구현: "32비트 정수만 스택, 나머지는 힙" ✅
성능 최적화: 가장 자주 쓰이는 32비트 정수만 특별 처리

🏆 최종 평가:
파차의 **"JS에서 원시 값은 스택에 저장되지 않습니다"**라는 표현은:

기술적으로 정확함 (32비트 정수 예외 있지만)
교육적으로 매우 유용함 (잘못된 통념 교정)
V8 소스코드로 완전히 입증됨

따라서 파차의 주장은 맞습니다! 🎯
```

</details>
